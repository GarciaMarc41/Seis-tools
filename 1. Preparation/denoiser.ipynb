{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005e6d8-eeb5-4c6c-944c-27f728d01253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "import seisbench.models as sbm\n",
    "\n",
    "# Load the model\n",
    "model = sbm.DeepDenoiser.from_pretrained(\"original\")\n",
    "\n",
    "# Define the source and target directories\n",
    "source_directory = '/Users/marcgarcia/Research/Picking/PhaseNet/Data/Raw'\n",
    "target_directory = '/Users/marcgarcia/Research/Picking/PhaseNet/Data/Denoised/'\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# Get all miniseed files\n",
    "mseed_files = [f for f in os.listdir(source_directory) if f.endswith('.mseed')]\n",
    "\n",
    "# Sort files by their names\n",
    "mseed_files.sort()\n",
    "\n",
    "# Loop through each sorted file\n",
    "for filename in mseed_files:\n",
    "    file_path = os.path.join(source_directory, filename)\n",
    "    \n",
    "    # Read the stream\n",
    "    stream = read(file_path)\n",
    "\n",
    "    # Apply the model to denoise\n",
    "    denoised = model.annotate(stream)\n",
    "\n",
    "    # Edit Traces\n",
    "    for trace in denoised:\n",
    "        if 'DeepDenoiser_' in trace.stats.channel:\n",
    "            trace.stats.channel = trace.stats.channel.replace('DeepDenoiser_', '')\n",
    "    \n",
    "    target_file_path = os.path.join(target_directory, filename)\n",
    "    \n",
    "    # Write denoised signals to the target directory\n",
    "    denoised.write(target_file_path, format='MSEED')\n",
    "\n",
    "    print(f'Processed and saved {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8096468f-3ca1-4219-9d85-85f517d631d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Processed and saved 2017-09-06T01-00-00.mseed\n",
      "Processed and saved 2017-09-06T00-00-00.mseed\n",
      "Processed and saved 2017-09-06T04-00-00.mseed\n",
      "Processed and saved 2017-09-06T06-00-00.mseed\n",
      "Processed and saved 2017-09-06T03-00-00.mseed\n",
      "Processed and saved 2017-09-06T02-00-00.mseed\n",
      "Processed and saved 2017-09-06T05-00-00.mseed\n",
      "Processed and saved 2017-09-06T08-00-00.mseed\n",
      "Processed and saved 2017-09-06T07-00-00.mseed\n",
      "Processed and saved 2017-09-06T09-00-00.mseed\n",
      "Processed and saved 2017-09-06T10-00-00.mseed\n",
      "Processed and saved 2017-09-06T11-00-00.mseed\n",
      "Processed and saved 2017-09-06T12-00-00.mseed\n",
      "Processed and saved 2017-09-06T13-00-00.mseed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from obspy import read\n",
    "import seisbench.models as sbm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4ecbae-9fbb-455b-9d88-52966a1a494b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Process the results as they complete\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(future_to_file):\n\u001b[1;32m     58\u001b[0m     filename \u001b[38;5;241m=\u001b[39m future_to_file[future]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Using ThreadPoolExecutor to process files in parallel\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnum_threads) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Submit all the tasks to the executor\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     future_to_file \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_file, filename, source_directory, target_directory, model): filename \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m mseed_files}\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Process the results as they complete\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from obspy import read\n",
    "import seisbench.models as sbm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Set the number of threads for PyTorch to n-1 (where n is the total number of performance cores on your CPU)\n",
    "torch.set_num_threads(7)  # Adjust this based on your CPU's core count if different\n",
    "\n",
    "# Function to process each file\n",
    "def process_file(filename, source_directory, target_directory, model):\n",
    "    file_path = os.path.join(source_directory, filename)\n",
    "    \n",
    "    # Read the stream\n",
    "    stream = read(file_path)\n",
    "\n",
    "    # Apply the model to denoise\n",
    "    denoised = model.annotate(stream)\n",
    "\n",
    "    # Edit Traces\n",
    "    for trace in denoised:\n",
    "        if 'DeepDenoiser_' in trace.stats.channel:\n",
    "            trace.stats.channel = trace.stats.channel.replace('DeepDenoiser_', '')\n",
    "    \n",
    "    target_file_path = os.path.join(target_directory, filename)\n",
    "    \n",
    "    # Write denoised signals to the target directory\n",
    "    denoised.write(target_file_path, format='MSEED')\n",
    "    \n",
    "    print(f'Processed and saved {filename}')\n",
    "\n",
    "# Load the model\n",
    "model = sbm.DeepDenoiser.from_pretrained(\"original\")\n",
    "\n",
    "# Define the source and target directories\n",
    "source_directory = '/Users/marcgarcia/Research/Picking/PhaseNet/Data/Raw'\n",
    "target_directory = '/Users/marcgarcia/Research/Picking/PhaseNet/Data/Denoised/'\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# Get all miniseed files\n",
    "mseed_files = [f for f in os.listdir(source_directory) if f.endswith('.mseed')]\n",
    "\n",
    "# Sort files by their names\n",
    "mseed_files.sort()\n",
    "\n",
    "# Number of threads to use for parallel processing - adjust based on experimentation\n",
    "num_threads = 7\n",
    "\n",
    "# Using ThreadPoolExecutor to process files in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit all the tasks to the executor\n",
    "    future_to_file = {executor.submit(process_file, filename, source_directory, target_directory, model): filename for filename in mseed_files}\n",
    "    \n",
    "    # Process the results as they complete\n",
    "    for future in as_completed(future_to_file):\n",
    "        filename = future_to_file[future]\n",
    "        try:\n",
    "            # Retrieve result (if any)\n",
    "            result = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'{filename} generated an exception: {exc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8320231-9f04-4f0f-bc8f-2a08e6907525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read stream\n",
    "stream = read('/Users/marcgarcia/Research/Picking/PhaseNet/Data/Denoised/2017-09-06T00-00-00.mseed')\n",
    "print(stream.__str__(extended=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f0d25-89d1-4a75-ad6b-d64072b1d1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "stream = read(\"/Users/marcgarcia/Research/Picking/PhaseNet/Data/Denoised/2017-09-06T00-00-00.mseed\")\n",
    "for trace in stream:\n",
    "    print(trace.stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929a760-0778-4738-ae5e-53a80d6b9ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "stream = read(\"/Users/marcgarcia/Research/Picking/PhaseNet/Data/Raw/2017-09-06T00-00-00.mseed\")\n",
    "print(stream)\n",
    "for trace in stream:\n",
    "    print(trace.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904eee3-080b-47e5-a6ad-7fd881f2a462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
